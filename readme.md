ğŸš€ PulseDesk AI â€” Customer Support Ticket Classifier

PulseDesk AI is a lightweight, production-ready machine-learning customer support classifier designed to automatically categorize incoming support messages into predefined ticket types.

It features:
	â€¢	ğŸ”¥ DistilBERT-based classifier (fine-tuned)
	â€¢	ğŸŒ Modern responsive UI
	â€¢	ğŸ³ Dockerized backend + frontend
	â€¢	â˜ï¸ Live deployment on AWS EC2
	â€¢	ğŸ”„ Fully automated CI/CD with GitHub Actions
	â€¢	âš¡ 1-click deploys on every push to main
	â€¢	ğŸ“ˆ Real-time prediction confidence
	â€¢	ğŸ—‚ï¸ Ticket history + clearing

Live Demo
ğŸ‘‰ http://23.23.72.235/

â¸»

ğŸ§  How PulseDesk AI Works
	1.	User enters a customer message.
	2.	The backend (/predict) loads the DistilBERT model and predicts:
	â€¢	Category (e.g., Account, Technical, Payments, etc.)
	â€¢	Confidence score
	â€¢	Raw probability distribution
	3.	The UI displays the result + adds it to ticket history.
	4.	You can clear history instantly.

â¸»

ğŸ—ï¸ Project Architecture

PulseDesk AI
â”‚
â”œâ”€â”€ Backend API  (FastAPI + DistilBERT)
â”‚     â”œâ”€â”€ Dockerfile
â”‚     â”œâ”€â”€ app/
â”‚     â”‚    â”œâ”€â”€ main.py
â”‚     â”‚    â””â”€â”€ model loader + classifier
â”‚     â””â”€â”€ model/ (ignored in repo)
â”‚
â”œâ”€â”€ Frontend UI (HTML/CSS/JS)
â”‚     â”œâ”€â”€ index.html
â”‚     â”œâ”€â”€ Dockerfile
â”‚     â””â”€â”€ assets/
â”‚
â”œâ”€â”€ CI/CD (GitHub Actions)
â”‚     â””â”€â”€ deploy.yml
â”‚
â””â”€â”€ AWS EC2 Deployment
      â”œâ”€â”€ Backend â†’ port 8000
      â””â”€â”€ UI â†’ port 80


â¸»

ğŸ³ Running Locally (Docker)

1. Build API

docker build -t pulsedesk-api .
docker run -p 8000:8000 pulsedesk-api

2. Build UI

docker build -t pulsedesk-ui ./ui
docker run -p 80:80 pulsedesk-ui


â¸»

ğŸŒ Live Deployment â€” AWS EC2

PulseDesk AI is deployed using:
	â€¢	Amazon EC2 (Ubuntu)
	â€¢	Docker Engine
	â€¢	Automatically started with CI/CD
	â€¢	Hosted at:

ğŸ‘‰ http://23.23.72.235/

Every deployment includes:
	â€¢	ğŸš€ Build backend image
	â€¢	ğŸš€ Build UI image
	â€¢	ğŸ” Stop old containers
	â€¢	â™»ï¸ Prune unused images

No manual login needed.

â¸»

ğŸ”„ CI/CD Pipeline (GitHub Actions)

Every push to main triggers the pipeline:

Set up job â†’ Checkout â†’ SSH Setup â†’ Rsync to EC2 â†’ Build images â†’ Restart containers

Secrets used:

Name	Purpose
EC2_HOST	Public IP of server
EC2_USERNAME	Usually ubuntu
EC2_SSH_KEY	Private key for SSH auth

Pipeline file:
.github/workflows/deploy.yml

â¸»

ğŸ§ª API Usage Example

POST /predict

curl -X POST "http://23.23.72.235:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"text": "My account is not working"}'

Sample response:

{
  "label": "Account",
  "confidence": 0.74,
  "all_probabilities": [0.74, 0.10, 0.08, 0.08]
}


â¸»

ğŸ“ Repository Structure

.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â”œâ”€â”€ utils.py
â”‚
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ static/
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ .github/workflows/deploy.yml


â¸»

ğŸ›‘ Model Files & Deployment

The DistilBERT model is **automatically downloaded from Google Drive** during container startup.

### For Local Development:

**Option 1: Let Docker handle it (Recommended)**
```bash
docker build -t pulsedesk-api .
docker run -p 8000:8000 pulsedesk-api
```
The container will automatically download the model on first run.

**Option 2: Manual download**
```bash
# Install gdown
pip install gdown

# Download model
gdown 1t-X6C2vL94D-m4e2Thd2HDclcbaPLN47 --fuzzy -O model.zip
unzip model.zip
rm model.zip
```

### For Production Deployment:

The model is automatically downloaded during deployment via the `download_model.sh` script.

**GitHub Secrets Required:**
- `EC2_HOST` - Public IP of your server
- `EC2_USERNAME` - Usually `ubuntu`
- `EC2_SSH_KEY` - Private SSH key for authentication
- `GDRIVE_FILE_ID` - Google Drive file ID (default: `1t-X6C2vL94D-m4e2Thd2HDclcbaPLN47`)

### Deploying to Other Platforms:

This setup works on **any** platform that supports Docker:
- âœ… AWS ECS/Fargate, Lambda (via container)
- âœ… Google Cloud Run
- âœ… Azure Container Instances
- âœ… Railway, Render, Fly.io
- âœ… DigitalOcean App Platform
- âœ… Heroku Container Registry

Simply set the `GDRIVE_FILE_ID` environment variable during deployment.

â¸»

ğŸš€ Roadmap
	â€¢	âœ” Auto ticket flagging
	â€¢	âœ” Confidence scoring
	â€¢	â¬œ Admin dashboard
	â€¢	â¬œ Batch classification API
	â€¢	â¬œ Add email â†’ ticket ingestion
	â€¢	â¬œ Add S3-hosted model versioning
	â€¢	â¬œ Migrate UI to React

â¸»

ğŸ‘¨ğŸ¾â€ğŸ’» Author

David Osei Kumi
AI/ML Engineer â€¢ Cloud Enthusiast â€¢ DevOps-in-Progress
GitHub: https://github.com/dkumi12/
